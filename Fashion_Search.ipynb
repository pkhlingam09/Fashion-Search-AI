{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXqBw5vjkM53oX6iE8JcON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkhlingam09/Fashion-Search-AI/blob/main/Fashion_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset Link (Kaggle)\n",
        "# https://www.kaggle.com/datasets/djagatiya/myntra-fashion-product-dataset"
      ],
      "metadata": {
        "id": "jCf3KIRDQrKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lt8Zk9TlVxHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################################################################################################################################################################\n",
        "###################################################################################################   MYNTRA ASSIGNMENT   ###################################################################################################"
      ],
      "metadata": {
        "id": "IqvZ9-tUVf8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Fashion_Search_AI/\""
      ],
      "metadata": {
        "id": "nQORNGpW13-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gmC0C7Ik1Rz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset():\n",
        "  !pip install -q kaggle chromadb\n",
        "  files.upload()\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "  !cat ~/.kaggle/kaggle.json\n",
        "  !kaggle datasets download \"djagatiya/myntra-fashion-product-dataset\" -p file_path\n",
        "  !unzip file_path+\"myntra-fashion-product-dataset.zip\" -d file_path"
      ],
      "metadata": {
        "id": "B2EdhvwOVTYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb"
      ],
      "metadata": {
        "id": "dR3taXQTUS0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import string\n",
        "import re\n",
        "import ast\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
        "\n",
        "from openai import OpenAI\n",
        "from sentence_transformers import CrossEncoder, util"
      ],
      "metadata": {
        "id": "WwIxCKaGk8qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_model = \"gpt-4o-mini\"\n",
        "moderator = \"omni-moderation-latest\""
      ],
      "metadata": {
        "id": "hBcL4e_14hhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path + \"Fashion Dataset v2.csv\")"
      ],
      "metadata": {
        "id": "VN8HU32Yk8l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "e4wd2cYok8jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "cJWPVPOrk8g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sahxXau0k8aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "ehnBuS79k8ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(100 * df.isna().sum()/df.shape[0], 3)"
      ],
      "metadata": {
        "id": "1t6iuQxXRFoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "wDCqRvork8U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "1RI2869Zk8P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class clean_datas:\n",
        "\n",
        "  def cleandata(self, df):\n",
        "    df[\"products\"] = df[\"products\"].str.lower()\n",
        "    df[\"colour\"] = df[\"colour\"].str.lower()\n",
        "    df[\"brand\"] = df[\"brand\"].str.lower()\n",
        "    self.clean_description(df)\n",
        "    self.clean_p_attributes(df)\n",
        "    self.merge_cols(df)\n",
        "\n",
        "  ## clean description column\n",
        "  def clean_description(self, df):\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: x.lower())\n",
        "    htmltags = re.compile(\"(<.*?>)|&nbsp;|&amp;|[;|]+\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(htmltags, \", \", x))\n",
        "    puncts = re.compile(r\"[ \\(\\)]+\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(puncts, \" \", x))\n",
        "    s_quote = re.compile(r\"[',]{2,}|(, ,)+\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(s_quote, \"\", x))\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\"(?i)(size s)\", \"size s, \", x))\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\"(?i)(size m)\", \"size m, \", x))\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\"(?i)(size l)\", \"size l, \", x))\n",
        "    spaces = re.compile(r\" {2,}\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(spaces, \" \", x).strip())\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\" *,$\", \"\", x))\n",
        "\n",
        "  ## Clean p_attributes column\n",
        "  def clean_p_attributes(self, df):\n",
        "    dict_list = []\n",
        "    pattr_keys_toremove = [\"body shape id\", \"body or garment size\"]\n",
        "\n",
        "    htmltags = re.compile(r\"(<.*?>)?(\\\\r|\\\\n)\")\n",
        "    df[\"p_attributes\"] = df[\"p_attributes\"].apply(lambda x: re.sub(htmltags, \" \", x))\n",
        "    if not isinstance(df.loc[0, \"p_attributes\"], dict):\n",
        "      df['p_attributes'] = df['p_attributes'].apply(lambda x: ast.literal_eval(x))\n",
        "    ## Remove Chosen keys from dictionaries\n",
        "    df[\"p_attributes\"] = [{key.lower(): val.lower() for key, val in dicts.items() if key.lower() not in pattr_keys_toremove and val != 'NA' and val != 'None' and val != ''} for dicts in list(df[\"p_attributes\"].values)]\n",
        "    ## Convert to String and Replace\n",
        "    df[\"p_attributes\"] = df[\"p_attributes\"].astype(\"str\")\n",
        "    df[\"p_attributes\"] = df['p_attributes'].replace({\":\": \" is \", \",\": \".\", \"[{}\\']\": \"\", \" +\": \" \"}, regex=True)\n",
        "    df[\"p_attributes\"] = df[\"p_attributes\"].apply(lambda x: x.lower())\n",
        "\n",
        "  ## Merge columns Product name, Products, price with description column\n",
        "  def merge_cols(self, df):\n",
        "    df[\"metadata\"] = df.apply(lambda x: {\"products\": x[\"products\"], \"colour\": x[\"colour\"], \"brand\": x[\"brand\"], \"price\": x[\"price\"]}, axis=1)\n",
        "    for ind in range(0, df.shape[0]):\n",
        "      df.loc[ind, \"description\"] = f\"Product name is {df['name'][ind]}.\" + df.loc[ind, \"description\"] + f\"{df['p_attributes'][ind]}\"\n"
      ],
      "metadata": {
        "id": "aSK5jZ82jdME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleanData = clean_datas()\n",
        "cleanData.cleandata(df)"
      ],
      "metadata": {
        "id": "cTUTYM0r1_sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Find length for each row of description column\n",
        "df[\"desc_len\"] = df['description'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "qOtdLKbrDRgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['p_id'] = df['p_id'].astype(\"str\")"
      ],
      "metadata": {
        "id": "y5kwscQ7Vyiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myntra = df.drop([\"ratingCount\", \"avg_rating\", \"name\", \"p_attributes\", \"products\", \"price\", \"colour\", \"brand\", \"img\"], axis=1)"
      ],
      "metadata": {
        "id": "hF5t3esuCZP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myntra.head(5)"
      ],
      "metadata": {
        "id": "INrHcwLVDRbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myntra = myntra[[\"p_id\", \"description\", \"metadata\"]]"
      ],
      "metadata": {
        "id": "QaUevPbwCrE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myntra.head(5)"
      ],
      "metadata": {
        "id": "kvTARr-jXLJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ____________________________________________________________________________________________  EDA and Data Cleaning Complete  ____________________________________________________________________________________________"
      ],
      "metadata": {
        "id": "vmjsyk9TZjwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Embeddings using ChromaDB"
      ],
      "metadata": {
        "id": "_Cjt05P5DRYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = \"text-embedding-3-large\"\n",
        "cross_encode_model = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "api_file = file_path + \"api_key.txt\"\n",
        "threshold = 0.15"
      ],
      "metadata": {
        "id": "jbbPonwhS51n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenAI_Embeddings:\n",
        "\n",
        "  def __init__(self, model, api_path, folder_name):\n",
        "    if folder_name == \"chroma_db\":\n",
        "      self.client = chromadb.PersistentClient(path= file_path + folder_name)\n",
        "    elif folder_name == \"cache_db\":\n",
        "      self.client = chromadb.Client()\n",
        "    self.model = model\n",
        "    self.api_path = api_path\n",
        "    self.embedding_function = None\n",
        "    self.myntra_collections = None\n",
        "    self.create_my_embedding()\n",
        "\n",
        "  def get_api(self):\n",
        "    with open(self.api_path, \"r\") as fptr:\n",
        "      api_key = fptr.read()\n",
        "      fptr.close()\n",
        "    return api_key\n",
        "\n",
        "  def create_my_embedding(self):\n",
        "    self.embedding_function = OpenAIEmbeddingFunction(\n",
        "                                                        api_key = self.get_api(),\n",
        "                                                        model_name = self.model\n",
        "                                                     )\n",
        "\n",
        "  def create_get_collection(self, name):\n",
        "    ## Create or Load Chroma Collection\n",
        "    self.myntra_collections = self.client.get_or_create_collection(\n",
        "                                                            name = name,\n",
        "                                                            embedding_function = self.embedding_function\n",
        "                                                        )\n",
        "    return self.myntra_collections\n",
        "\n",
        "  def add_to_collection(self, data, collections):\n",
        "    ## Add data to Chroma Collection\n",
        "    prev = 0\n",
        "    docs_list = data[\"description\"].to_list()\n",
        "    meta_list = data['metadata'].to_list()\n",
        "    id_list = data['p_id'].to_list()\n",
        "    ## Add data to Chroma Collection\n",
        "    for batch_size in range(1000, len(docs_list), 1000):\n",
        "      collections.add(\n",
        "                                    documents = docs_list[prev:batch_size],\n",
        "                                    metadatas = meta_list[prev:batch_size],\n",
        "                                    ids = id_list[prev:batch_size]\n",
        "                                 )\n",
        "      prev = batch_size\n",
        "    if prev < len(docs_list):\n",
        "      collections.add(\n",
        "                                     documents = docs_list[prev:],\n",
        "                                     metadatas = meta_list[prev:],\n",
        "                                     ids = id_list[prev:]\n",
        "                                 )\n",
        "    return collections"
      ],
      "metadata": {
        "id": "QscuSwemEh4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chroma_Search(OpenAI_Embeddings):\n",
        "\n",
        "  def __init__(self, model, api_path, folder_name):\n",
        "    super().__init__(model, api_path, folder_name)\n",
        "\n",
        "  def text_query(self, collections, query, w_clause=None, w_doc_clause=None):\n",
        "    query_results = collections.query(\n",
        "                                          query_texts = [query],\n",
        "                                          n_results = 10,\n",
        "                                          where = w_clause,\n",
        "                                          where_document = w_doc_clause\n",
        "                                     )\n",
        "    return query_results"
      ],
      "metadata": {
        "id": "MxvzEbajEhz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This embedding model is to create embeddings and query\n",
        "myntra_obj = Chroma_Search(embed_model, api_file, \"chroma_db\")\n",
        "myntra_collection = myntra_obj.create_get_collection(\"myntra\")\n",
        "\n",
        "if not os.path.isdir(file_path + \"chroma_db\"):\n",
        "  myntra_obj.add_to_collection(myntra, myntra_collection)\n",
        "\n",
        "myntra_collection.peek()"
      ],
      "metadata": {
        "id": "T0vZrHvMM4IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This embedding model is to create cache and query\n",
        "cache_collections = []\n",
        "collection_names = [\"cache_1\", \"cache_2\", \"cache_3\", \"cache_4\", \"cache_5\"]\n",
        "\n",
        "cache_obj = Chroma_Search(embed_model, api_file, \"cache_db\")\n",
        "for name in collection_names:\n",
        "  cache_collections.append(cache_obj.create_get_collection(name))"
      ],
      "metadata": {
        "id": "XnPAFcILvmEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_collections[0].peek()"
      ],
      "metadata": {
        "id": "pzC3BcWxW-uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prompt Generation using OpenAI"
      ],
      "metadata": {
        "id": "kVB7YEJqrERC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_client = OpenAI(api_key=myntra_obj.get_api())"
      ],
      "metadata": {
        "id": "JKIijNnirEMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fashion_converse(conversation):\n",
        "    chat_resp = chat_client.chat.completions.create(\n",
        "                                    model = gpt_model,\n",
        "                                    messages = conversation,\n",
        "                                    temperature = 0.4,\n",
        "                                    max_tokens = 300,\n",
        "                                    tools = tools_shop_assist(),\n",
        "                                    tool_choice = \"auto\"\n",
        "                                    )\n",
        "    return chat_resp.choices[0].message\n",
        "\n",
        "def chat_moderator(msg):\n",
        "    response = chat_client.moderations.create(\n",
        "                                    model = moderator,\n",
        "                                    input = msg\n",
        "                                    )\n",
        "\n",
        "    return response.results[0].flagged"
      ],
      "metadata": {
        "id": "apYMkdFPrEKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_queries(inp_query_dict):\n",
        "  query_list = []\n",
        "\n",
        "  query = inp_query_dict[\"inp_query\"]\n",
        "  attr_dict_ = ast.literal_eval(inp_query_dict[\"attr_dict\"])\n",
        "  query = f'{query}. {inp_query_dict[\"addn_info\"]}'\n",
        "\n",
        "  for key, vals in attr_dict_.items():\n",
        "    if key == \"products\" and attr_dict_[key] != []:\n",
        "      if len(attr_dict_[key][0]) == 1:\n",
        "        query_list.append({\"products\": {\"$eq\": attr_dict_[key]}})\n",
        "      else:\n",
        "        temp = [{key: {\"$eq\": ', '.join(attr_dict_[key])}}]\n",
        "        temp.extend([{key: {\"$eq\": prod}} for prod in attr_dict_[key]])\n",
        "        query_list.append({\"$or\": temp})\n",
        "    if key == \"colour\" and attr_dict_[key] != []:\n",
        "      if len(attr_dict_[key][0]) == 1:\n",
        "        query_list.append({key: {\"$eq\": attr_dict_[key]}})\n",
        "      else:\n",
        "        query_list.append({\"$or\": [{key: {\"$eq\": color}} for color in attr_dict_[key]]})\n",
        "    elif key == \"brand\" and attr_dict_[key] != []:\n",
        "      query_list.append({key: {\"$eq\": attr_dict_[key]}})\n",
        "    elif key == \"price\" and attr_dict_[key] != []:\n",
        "      query_list.append({\"price\": {\"$lte\": float(attr_dict_[key])}})\n",
        "  return query, {\"$and\": query_list}"
      ],
      "metadata": {
        "id": "fQnbSO4solxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_track = 0\n",
        "def user_queries(query, attr_dict, w_doc_clause):\n",
        "  global ind_track\n",
        "  ids = []\n",
        "  documents = []\n",
        "  distances = []\n",
        "  metadatas = []\n",
        "\n",
        "  cache_result = [cache_obj.text_query(cache_collection, query, attr_dict, w_doc_clause) for cache_collection in cache_collections if len(cache_collection.peek()[\"ids\"])]\n",
        "  cache_ind = [ind for ind, result in enumerate(cache_result) if result['distances'][0] != [] and result['distances'][0][0] <= threshold]\n",
        "  if len(cache_ind) != 0:\n",
        "    for ind in cache_ind:\n",
        "      cache_result_dict = cache_result[ind]['metadatas'][0][0]\n",
        "      # Loop through each inner list and then through the dictionary\n",
        "      for key, value in cache_result_dict.items():\n",
        "          if 'ids' in key:\n",
        "            ids.append(value)\n",
        "          elif 'documents' in key:\n",
        "              documents.append(value)\n",
        "          elif 'distances' in key:\n",
        "              distances.append(value)\n",
        "          elif 'metadatas' in key:\n",
        "              metadatas.append(value)\n",
        "\n",
        "    # Create a DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "      'IDs': ids,\n",
        "      'Documents': documents,\n",
        "      'Distances': distances,\n",
        "      'Metadatas': metadatas\n",
        "    })\n",
        "    results_df.drop_duplicates(subset=\"IDs\", inplace=True)\n",
        "    return results_df\n",
        "  else:\n",
        "    results = myntra_obj.text_query(myntra_collection, query, attr_dict, w_doc_clause)\n",
        "    if not len(results):\n",
        "      return None\n",
        "    keys = []\n",
        "    vals = []\n",
        "    for key, val in results.items():\n",
        "      if val == None:\n",
        "        continue\n",
        "      if key.lower() != \"embeddings\" and key.lower() != \"uris\" and key.lower() != \"data\" and key.lower() != \"included\":\n",
        "        for i in range(0, len(results[\"ids\"][0])):\n",
        "              keys.append(str(key)+str(i))\n",
        "              vals.append(str(val[0][i]))\n",
        "      ## Add new query to collection\n",
        "    count = 1\n",
        "    for cache_collection in cache_collections:\n",
        "      count += count + 1\n",
        "      if not len(cache_collection.peek()[\"ids\"]):\n",
        "        cache_collection.add(\n",
        "                              documents = [query],\n",
        "                              ids = [query],\n",
        "                              metadatas =  dict(zip(keys, vals))\n",
        "                            )\n",
        "        break\n",
        "    if count < 5:\n",
        "      cache_collection = cache_collections[ind_track]\n",
        "      ind_track += 1\n",
        "      if ind_track == 4:\n",
        "        ind_track = 0\n",
        "      cache_collection.add(\n",
        "                            documents = [query],\n",
        "                            ids = [query],\n",
        "                            metadatas =  dict(zip(keys, vals))\n",
        "                          )\n",
        "    ## Create Result database\n",
        "    result_dict = {'Metadatas': results['metadatas'][0], 'Documents': results['documents'][0], 'Distances': results['distances'][0], \"IDs\":results[\"ids\"][0]}\n",
        "    results_df = pd.DataFrame.from_dict(result_dict)\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "C5aTySB00vSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cross-Encoders\n",
        "def crossencode_user_query(df, query):\n",
        "  cross_encoder = CrossEncoder(cross_encode_model)\n",
        "  scores = cross_encoder.predict([[query, response] for response in df['Documents']])\n",
        "  df['cross_encoder_scores'] = scores\n",
        "  df.sort_values(by='cross_encoder_scores', ascending=False, inplace=True)\n",
        "  return df[[\"Metadatas\", \"Documents\"]]"
      ],
      "metadata": {
        "id": "a6wjfAmGCrvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_query_data(inp_query_dict):\n",
        "  attr_dict_ = ast.literal_eval(inp_query_dict[\"attr_dict\"])\n",
        "\n",
        "  for key, val in attr_dict_.copy().items():\n",
        "    if isinstance(val, list):\n",
        "      if len(val) == 1:\n",
        "        attr_dict_[key] = val[0]\n",
        "      elif isinstance(val, str) and \",\" in val:\n",
        "        val = val.split(\",\")\n",
        "        val = val.replace(\" \", \"\")\n",
        "        attr_dict_[key] = val\n",
        "      elif val == \"\":\n",
        "        attr_dict_[key] = []\n",
        "  inp_query_dict[\"attr_dict\"] = str(attr_dict_)\n",
        "  return inp_query_dict"
      ],
      "metadata": {
        "id": "yBRap-bfw68Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_products(inp_query_dict):\n",
        "  inp_query_dict = format_query_data(inp_query_dict)\n",
        "  query, inp_dict = create_queries(inp_query_dict)\n",
        "  df = user_queries(query, inp_dict, None)\n",
        "  return crossencode_user_query(df, query)"
      ],
      "metadata": {
        "id": "u5j-zZSUkMS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Belongs in Tools_Calls Class\n",
        "\n",
        "def tools_shop_assist():\n",
        "        criteria = [\n",
        "                        {\n",
        "                            \"type\": \"function\",\n",
        "                            \"function\": {\n",
        "                                \"name\": \"list_products\",\n",
        "                                \"description\": \"Function takes input string and additional criteria as input and returns \",\n",
        "                                \"strict\": False,\n",
        "                                \"parameters\": {\n",
        "                                    \"type\": \"object\",\n",
        "                                    \"properties\": {\n",
        "                                        \"inp_query\": {\n",
        "                                            \"type\": \"string\",\n",
        "                                            \"description\": \"string indicating input given by user eg. find all the skirts in pink.\",\n",
        "                                        },\n",
        "                                        \"attr_dict\": {\n",
        "                                            \"type\": \"string\",\n",
        "                                            \"description\": \"features the apparel needs to have. eg. {'size': 'long', 'colour': 'pink', 'design': 'floral'}.\",\n",
        "                                        },\n",
        "                                        \"addn_info\": {\n",
        "                                            \"type\": \"string\",\n",
        "                                            \"description\": \"string additional requirements given by the user eg. size should be small and closure will be zipper\",\n",
        "                                        },\n",
        "                                    },\n",
        "                                    \"required\": [\"inp_query\", \"attr_dict\", \"addn_info\"],\n",
        "                                    \"additionalProperties\": False\n",
        "                                },\n",
        "                            },\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "        return criteria\n"
      ],
      "metadata": {
        "id": "HK83wlpCrECt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_conversation():\n",
        "    delimiters = \"#####\"\n",
        "    core_ask = [\"products\", \"colour\", \"brand\", \"price\"]\n",
        "\n",
        "    chat_prompt = f\"\"\"\n",
        "                      You new an expert in Fashion Digital Marketer, Fashion Merchandise, Stylist and E-commerce Consultant.Your job is to assist customers find the apparel they want to buy through polite and professional conversation.\n",
        "                      {delimiters}\n",
        "                      Enquire customer about each of the criteria in the list {core_ask}. If the response is not clear, rephrase the question and ask again.\n",
        "                      Values for all the criteria have to be extracted from customer, missing any of the criteria will be penalised.\n",
        "                      ''' Showing the summary and internal information will be penalised. '''\n",
        "                      (If the values for any criteria contains 'and' or any punctuations except '-', split them.)\n",
        "                      (If the values for any criteria contains 'no' or 'none' or 'any', replace them with empty list such as '[]'.)\n",
        "                      (If there are multiple values for a criteria, save the values as list of values. Not saving them as list of values will be penalised.)\n",
        "                      Once the data is collected from customer, convert the criteria and the answers received for the criteria into a dictionary format.\n",
        "                      ''' Showing the summary and internal information will be penalised. '''\n",
        "                      Once all the data is collected, ask the customer (if he wants to add any other information. if yes allow customer to add details and save it as a string). else proceed.\n",
        "                      Call function list_products() with arguments as the complete input string by customer and additional criteria and answers stored in dictionary earlier.\n",
        "                      list_products() function returns a dataframe, which consists of one product in every row. Take the details of product from all columns in each row and display them Product name, products available and total price in rupees details for each product in each row and display them.\n",
        "                      {delimiters}\n",
        "                      Examples of how to display the final output:\n",
        "                      Product            Products Available            Price\n",
        "                      xyzlb              a, b, c                       Rs.54\n",
        "                      mnopkqhgy          a                             Rs.2710\n",
        "                      qwp                a, b, c, d                    Rs.89433\n",
        "                      {delimiters}\n",
        "                   \"\"\"\n",
        "    chat_prompt = [{\"role\": \"system\", \"content\": chat_prompt},\n",
        "                   {\"role\": \"user\", \"content\": f\"Start conversation with a polite welcome and enquiring about the criteria in the list {core_ask} one at a time\"}]\n",
        "\n",
        "    return chat_prompt\n"
      ],
      "metadata": {
        "id": "EZtUbRCirEFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_conversations():\n",
        "  converse = initial_conversation()\n",
        "  chat_resp = fashion_converse(converse)\n",
        "  converse.append({\"role\": \"assistant\", \"content\": str(chat_resp.content)})\n",
        "  print(chat_resp.content)\n",
        "\n",
        "  while True:\n",
        "    user_input = input().lower().strip()\n",
        "    if user_input == \"exit\":\n",
        "      break\n",
        "\n",
        "    is_flagged = chat_moderator(user_input)\n",
        "    if is_flagged:\n",
        "        print(\"Sorry, this message has been flagged. Cannot be accepted.\")\n",
        "        continue ## Skip everything and get back to input()\n",
        "\n",
        "    converse.append({\"role\": \"user\", \"content\": user_input})\n",
        "    chat_resp = fashion_converse(converse)\n",
        "    if chat_resp.tool_calls:\n",
        "      for tool_call in chat_resp.tool_calls:\n",
        "        func_name = tool_call.function.name\n",
        "        args = json.loads(tool_call.function.arguments)\n",
        "        tool_response = list_products(args)\n",
        "        ## Append Function Calling Request\n",
        "        converse.append(chat_resp)\n",
        "        converse.append({\n",
        "                        \"role\": \"tool\",\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"name\": func_name,\n",
        "                        \"content\": str(tool_response)\n",
        "                        })\n",
        "      chat_resp = fashion_converse(converse)\n",
        "      print(chat_resp.content)\n",
        "    else:\n",
        "      converse.append({\"role\": \"assistant\", \"content\": str(chat_resp.content)})\n",
        "      print(chat_resp.content)\n"
      ],
      "metadata": {
        "id": "UHQ4lQ2qrEAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_conversations()"
      ],
      "metadata": {
        "id": "e4DaxKcQ08kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7IqNvbbN08G2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}