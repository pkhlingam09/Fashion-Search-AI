{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbZKV6z0MHi8cR84woF95v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkhlingam09/Fashion-Search-AI/blob/Final_Done_0405/Fashion_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset Link (Kaggle)\n",
        "# https://www.kaggle.com/datasets/djagatiya/myntra-fashion-product-dataset"
      ],
      "metadata": {
        "id": "jCf3KIRDQrKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# def find_file(root_dir, file_name):\n",
        "#     for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "#         if file_name in filenames:\n",
        "#             return os.path.join(dirpath, file_name)\n",
        "#     return None\n",
        "\n",
        "# file_path = find_file(\"/\", \"Fashion Dataset v2.csv\") #Searches from the root directory\n",
        "\n",
        "# if file_path:\n",
        "#   print(file_path)\n",
        "# else:\n",
        "#   print(\"File not found\")"
      ],
      "metadata": {
        "id": "u-LJ4X08VxPX",
        "outputId": "19ba4d5c-4f5b-4069-8593-a098361ae776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fashion_Search_AI/Fashion Dataset v2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f40OI7I6VxM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBK1Bt_gVxKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lt8Zk9TlVxHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################################################################################################################################################################\n",
        "###################################################################################################   MYNTRA ASSIGNMENT   ###################################################################################################"
      ],
      "metadata": {
        "id": "IqvZ9-tUVf8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-gmC0C7Ik1Rz",
        "outputId": "df63c15d-d78f-4a0b-e6a0-e29717bafe1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Fashion_Search_AI/\"\n",
        "\n",
        "def read_dataset():\n",
        "  !pip install -q kaggle chromadb\n",
        "  files.upload()\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "  !cat ~/.kaggle/kaggle.json\n",
        "  !kaggle datasets download \"djagatiya/myntra-fashion-product-dataset\" -p file_path\n",
        "  !unzip file_path+\"myntra-fashion-product-dataset.zip\" -d file_path"
      ],
      "metadata": {
        "id": "B2EdhvwOVTYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb"
      ],
      "metadata": {
        "id": "dR3taXQTUS0o",
        "outputId": "a4551294-2917-4d8b-d2c1-0b99000b1a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import string\n",
        "import re\n",
        "import ast\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import chromadb\n",
        "\n",
        "from openai import OpenAI\n",
        "from sentence_transformers import CrossEncoder, util"
      ],
      "metadata": {
        "id": "WwIxCKaGk8qV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_word = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "93gtLyb2YHme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_rows', 200)\n",
        "# pd.set_option('display.max_columns', 200)"
      ],
      "metadata": {
        "id": "nhj3nsjR9U-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_model = \"gpt-4o-mini\"\n",
        "moderator = \"omni-moderation-latest\""
      ],
      "metadata": {
        "id": "hBcL4e_14hhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path + \"Fashion Dataset v2.csv\")"
      ],
      "metadata": {
        "id": "VN8HU32Yk8l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "e4wd2cYok8jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "cJWPVPOrk8g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sahxXau0k8aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "ehnBuS79k8ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(100 * df.isna().sum()/df.shape[0], 3)"
      ],
      "metadata": {
        "id": "1t6iuQxXRFoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "wDCqRvork8U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "1RI2869Zk8P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class clean_data:\n",
        "\n",
        "  def __init__(self, df):\n",
        "    clean_description(df)\n",
        "    clean_p_attributes(df)\n",
        "    remove_chosen_keys(df)\n",
        "    merge_cols(df)\n",
        "\n",
        "  ## clean description column\n",
        "  def clean_description(self, df):\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: x.lower())\n",
        "    htmltags = re.compile(\"(<.*?>)|&nbsp;|&amp;|[;|]+\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(htmltags, \", \", x))\n",
        "    puncts = re.compile(r\"[ \\(\\)]+\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(puncts, \" \", x))\n",
        "    s_quote = re.compile(r\"[',]{2,}|(, ,)+\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(s_quote, \"\", x))\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\"(?i)(size s)\", \"size s, \", x))\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\"(?i)(size m)\", \"size m, \", x))\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\"(?i)(size l)\", \"size l, \", x))\n",
        "    spaces = re.compile(r\" {2,}\")\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(spaces, \" \", x).strip())\n",
        "    df[\"description\"] = df[\"description\"].apply(lambda x: re.sub(\" *,$\", \"\", x))\n",
        "\n",
        "  ## Clean p_attributes column\n",
        "  def clean_p_attributes(self, df):\n",
        "    df[\"p_attributes\"] = df[\"p_attributes\"].apply(lambda x: x.lower())\n",
        "    htmltags = re.compile(r\"(<.*?>)?(\\\\r|\\\\n)\")\n",
        "    df[\"p_attributes\"] = df[\"p_attributes\"].apply(lambda x: re.sub(htmltags, \" \", x))\n",
        "    re.sub(r\"(<.*?>)?(\\\\r|\\\\n)\", \" \", df.loc[956, \"p_attributes\"])\n",
        "    df['p_attributes'] = df['p_attributes'].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "  ## Remove Chosen keys from dictionaries\n",
        "  def remove_chosen_keys(self, df):\n",
        "    pattr_keys_toremove = [\"body shape id\", \"body or garment size\"]\n",
        "    for ind, dicts in enumerate(df[\"p_attributes\"].copy()):\n",
        "      for key in pattr_keys_toremove:\n",
        "        if key in dicts.keys():\n",
        "          del dicts[key]\n",
        "      df.loc[ind, \"p_attributes\"] = dicts\n",
        "\n",
        "  ## Merge columns Product name, Products, price with description column\n",
        "  def merge_cols(self, df):\n",
        "    for ind in range(0, df.shape[0]):\n",
        "      df.loc[ind, \"description\"] = f\"Product name is {df['name'][ind]}. Products available are {df['products'][ind]} for a total price of {df['price'][ind]}. Product colour is {df['colour'][ind]}. Brand is {df['brand'][ind]}. \" + df.loc[ind, \"description\"]\n"
      ],
      "metadata": {
        "id": "aSK5jZ82jdME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Find length for each row of description column\n",
        "df[\"pattr_len\"] = df.loc[:10, 'p_attributes'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "IRzHJuk2EgIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"desc_len\"] = df['description'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "qOtdLKbrDRgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "INrHcwLVDRbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['p_id'] = df['p_id'].astype(\"str\")"
      ],
      "metadata": {
        "id": "y5kwscQ7Vyiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myntra = df.drop([\"ratingCount\", \"avg_rating\", \"name\", \"products\", \"colour\", \"brand\", \"price\"], axis=1)"
      ],
      "metadata": {
        "id": "hF5t3esuCZP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myntra = myntra[[\"p_id\", \"description\", \"p_attributes\"]]"
      ],
      "metadata": {
        "id": "QaUevPbwCrE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ____________________________________________________________________________________________  EDA and Data Cleaning Complete  ____________________________________________________________________________________________\n",
        "# __________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "# __________________________________________________________________________________________________________________________________________________________________________________________________________________________"
      ],
      "metadata": {
        "id": "vmjsyk9TZjwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Embeddings using ChromaDB"
      ],
      "metadata": {
        "id": "_Cjt05P5DRYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = \"text-embedding-3-large\"\n",
        "cross_encode_model = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "api_file = file_path + \"api_key.txt\"\n",
        "threshold = 0.15"
      ],
      "metadata": {
        "id": "jbbPonwhS51n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = chromadb.PersistentClient(path= file_path + \"chroma_db\")"
      ],
      "metadata": {
        "id": "i8G7ZfOQEiAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenAI_Embeddings:\n",
        "\n",
        "  def __init__(self, model, api_path):\n",
        "    self.model = model\n",
        "    self.api_path = api_path\n",
        "    self.embedding_function = None\n",
        "    self.myntra_collections = None\n",
        "    self.create_my_embedding()\n",
        "\n",
        "  def get_api(self):\n",
        "    with open(self.api_path, \"r\") as fptr:\n",
        "      api_key = fptr.read()\n",
        "      fptr.close()\n",
        "    return api_key\n",
        "\n",
        "  def create_my_embedding(self):\n",
        "    self.embedding_function = OpenAIEmbeddingFunction(\n",
        "                                                        api_key = self.get_api(),\n",
        "                                                        model_name = self.model\n",
        "                                                     )\n",
        "\n",
        "  def create_get_collection(self, name):\n",
        "    ## Create or Load Chroma Collection\n",
        "    self.myntra_collections = client.get_or_create_collection(\n",
        "                                                            name = name,\n",
        "                                                            embedding_function = self.embedding_function\n",
        "                                                        )\n",
        "    return self.myntra_collections\n",
        "\n",
        "  def add_to_collection(self, data, collections):\n",
        "    ## Add data to Chroma Collection\n",
        "    prev = 0\n",
        "    docs_list = data[\"description\"].to_list()\n",
        "    meta_list = data['p_attributes'].to_list()\n",
        "    id_list = data['p_id'].to_list()\n",
        "    ## Add data to Chroma Collection\n",
        "    for batch_size in range(1000, len(docs_list), 1000):\n",
        "      collections.add(\n",
        "                                    documents = docs_list[prev:batch_size],\n",
        "                                    metadatas = meta_list[prev:batch_size],\n",
        "                                    ids = id_list[prev:batch_size]\n",
        "                                 )\n",
        "      prev = batch_size\n",
        "    if prev < len(docs_list):\n",
        "      collections.add(\n",
        "                                     documents = docs_list[prev:],\n",
        "                                     metadatas = meta_list[prev:],\n",
        "                                     ids = id_list[prev:]\n",
        "                                 )\n",
        "    return collections"
      ],
      "metadata": {
        "id": "QscuSwemEh4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chroma_Search(OpenAI_Embeddings):\n",
        "\n",
        "  def __init__(self, model, api_path):\n",
        "    super().__init__(model, api_path)\n",
        "\n",
        "  def text_query(self, collections, query, w_clause = \"\", w_doc_clause = \"\"):\n",
        "    query_results = collections.query(\n",
        "                                          query_texts = [query],\n",
        "                                          n_results = 10\n",
        "                                     )\n",
        "    return query_results"
      ],
      "metadata": {
        "id": "MxvzEbajEhz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This embedding model is to create embeddings and query\n",
        "myntra_obj = Chroma_Search(embed_model, api_file)\n",
        "myntra_collection = myntra_obj.create_get_collection(\"myntra\")\n",
        "\n",
        "if not os.path.isdir(file_path + \"chroma_db\"):\n",
        "  myntra_obj.add_to_collection(myntra, myntra_collection)\n",
        "\n",
        "myntra_collection.peek()"
      ],
      "metadata": {
        "id": "T0vZrHvMM4IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This embedding model is to create cache and query\n",
        "cache_obj = Chroma_Search(embed_model, api_file)\n",
        "cache_collection = cache_obj.create_get_collection(\"cache_myntra\")\n",
        "\n",
        "cache_collection.peek()"
      ],
      "metadata": {
        "id": "CfBFlHDE96Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_query(query, attr_dict, w_doc_clause):\n",
        "  ids = []\n",
        "  documents = []\n",
        "  distances = []\n",
        "  metadatas = []\n",
        "  results_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "  cache_result = cache_obj.text_query(cache_collection, query, attr_dict, w_doc_clause)\n",
        "\n",
        "  if cache_result['distances'][0] == []: # if cache is empty\n",
        "    result = myntra_obj.text_query(myntra_collection, query, attr_dict, w_doc_clause)\n",
        "\n",
        "    keys = []\n",
        "    vals = []\n",
        "    for key, val in result.items():\n",
        "      if val == None:\n",
        "        continue\n",
        "      if key.lower() != \"embeddings\" and key.lower() != \"uris\" and key.lower() != \"data\" and key.lower() != \"included\":\n",
        "        for i in range(10):\n",
        "              keys.append(str(key)+str(i))\n",
        "              vals.append(str(val[0][i]))\n",
        "      ## Add new query to collection\n",
        "        cache_collection.add(\n",
        "                              documents = [query],\n",
        "                              ids = [query],\n",
        "                              metadatas =  dict(zip(keys, vals))\n",
        "                            )\n",
        "        ## Create Result database\n",
        "        result_dict = {'Metadatas': results['metadatas'][0], 'Documents': results['documents'][0], 'Distances': results['distances'][0], \"IDs\":results[\"ids\"][0]}\n",
        "        results_df = pd.DataFrame.from_dict(result_dict)\n",
        "        results_df\n",
        "  else:\n",
        "    cache_result_dict = cache_result['metadatas'][0][0]\n",
        "\n",
        "    # Loop through each inner list and then through the dictionary\n",
        "    for key, value in cache_result_dict.items():\n",
        "        if 'ids' in key:\n",
        "            ids.append(value)\n",
        "        elif 'documents' in key:\n",
        "            documents.append(value)\n",
        "        elif 'distances' in key:\n",
        "            distances.append(value)\n",
        "        elif 'metadatas' in key:\n",
        "            metadatas.append(value)\n",
        "\n",
        "    # Create a DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "      'IDs': ids,\n",
        "      'Documents': documents,\n",
        "      'Distances': distances,\n",
        "      'Metadatas': metadatas\n",
        "    })\n",
        "    results_df"
      ],
      "metadata": {
        "id": "0wNFk7-Fvspp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ## Cross-Encoders"
      ],
      "metadata": {
        "id": "HYo3ZU3wCryJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossencode_user_query(df):\n",
        "  cross_encoder = CrossEncoder(cross_encode_model)\n",
        "  scores = cross_encoder.predict([[query, response] for response in results_df['Documents']])\n",
        "  results_df['cross_encoder_scores'] = scores\n",
        "  results_df.sort_values(by='cross_encoder_scores', ascending=False, inplace=True)\n",
        "  return results_df[[\"Metadatas\", \"Documents\"]]"
      ],
      "metadata": {
        "id": "a6wjfAmGCrvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prompt Generation using OpenAI"
      ],
      "metadata": {
        "id": "kVB7YEJqrERC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_client = OpenAI(api_key=myntra_obj.get_api())"
      ],
      "metadata": {
        "id": "JKIijNnirEMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fashion_converse(conversation):\n",
        "    chat_resp = chat_client.chat.completions.create(\n",
        "                                    model = gpt_model,\n",
        "                                    messages = conversation,\n",
        "                                    temperature = 0.4,\n",
        "                                    max_tokens = 200,\n",
        "                                    tools = tools_shop_assist(),\n",
        "                                    tool_choice = \"auto\"\n",
        "                                    )\n",
        "    return chat_resp.choices[0].message\n",
        "\n",
        "def chat_moderator(msg):\n",
        "    response = chat_client.moderations.create(\n",
        "                                    model = moderator,\n",
        "                                    input = msg\n",
        "                                    )\n",
        "\n",
        "    return response.results[0].flagged"
      ],
      "metadata": {
        "id": "apYMkdFPrEKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_products(inp_query_dict):\n",
        "  w_doc_clause = \"\"\n",
        "  inp_query = inp_query_dict[\"inp_query\"]\n",
        "  attr_dict = ast.literal_eval(inp_query_dict[\"attr_dict\"])\n",
        "  if \"colour\" in list(attr_dict.keys()):\n",
        "    w_doc_clause = {\"colour\": attr_dict['colour'].lower()}\n",
        "    del attr_dict['colour']\n",
        "  if \"size\" in list(attr_dict.keys()):\n",
        "    w_doc_clause = {\"size\": attr_dict['size'].lower()}\n",
        "    del attr_dict['size']\n",
        "  df = user_query(query, attr_dict, w_doc_clause)\n",
        "  return crossencode_user_query(df)"
      ],
      "metadata": {
        "id": "cv266_NvfU4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Belongs in Tools_Calls Class\n",
        "\n",
        "def tools_shop_assist():\n",
        "        criteria = [\n",
        "                        {\n",
        "                            \"type\": \"function\",\n",
        "                            \"function\": {\n",
        "                                \"name\": \"list_products\",\n",
        "                                \"description\": \"Function takes input string and additional criteria as input and returns \",\n",
        "                                \"strict\": False,\n",
        "                                \"parameters\": {\n",
        "                                    \"type\": \"object\",\n",
        "                                    \"properties\": {\n",
        "                                        \"inp_query\": {\n",
        "                                            \"type\": \"string\",\n",
        "                                            \"description\": \"string indicating input given by user eg. find all the skirts in pink.\",\n",
        "                                        },\n",
        "                                        \"attr_dict\": {\n",
        "                                            \"type\": \"string\",\n",
        "                                            \"description\": \"features the apparel needs to have. eg. {'size': 'long', 'colour': 'pink', 'design': 'floral'}.\",\n",
        "                                        },\n",
        "                                    },\n",
        "                                    \"required\": [\"inp_query\", \"attr_dict\"],\n",
        "                                    \"additionalProperties\": False\n",
        "                                },\n",
        "                            },\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "        return criteria\n"
      ],
      "metadata": {
        "id": "HK83wlpCrECt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_conversations():\n",
        "  converse = initial_conversation()\n",
        "  chat_resp = fashion_converse(converse)\n",
        "  converse.append({\"role\": \"assistant\", \"content\": str(chat_resp.content)})\n",
        "  print(chat_resp.content)\n",
        "\n",
        "  while True:\n",
        "    user_input = input().lower().strip()\n",
        "    if user_input == \"exit\":\n",
        "      break\n",
        "\n",
        "    is_flagged = chat_moderator(user_input)\n",
        "    if is_flagged:\n",
        "        print(\"Sorry, this message has been flagged. Cannot be accepted.\")\n",
        "        continue ## Skip everything and get back to input()\n",
        "\n",
        "    converse.append({\"role\": \"user\", \"content\": user_input})\n",
        "    chat_resp = fashion_converse(converse)\n",
        "    if chat_resp.tool_calls:\n",
        "      for tool_call in chat_resp.tool_calls:\n",
        "        func_name = tool_call.function.name\n",
        "        args = json.loads(tool_call.function.arguments)\n",
        "        tool_response = list_products(args)\n",
        "        ## Append Function Calling Request\n",
        "        converse.append(chat_resp)\n",
        "        converse.append({\n",
        "                        \"role\": \"tool\",\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"name\": func_name,\n",
        "                        \"content\": str(tool_response)\n",
        "                        })\n",
        "      chat_resp = fashion_converse(converse)\n",
        "      print(chat_resp.content)\n",
        "    else:\n",
        "      converse.append({\"role\": \"assistant\", \"content\": str(chat_resp.content)})\n",
        "      print(chat_resp.content)\n"
      ],
      "metadata": {
        "id": "UHQ4lQ2qrEAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_conversation():\n",
        "    delimiters = \"#####\"\n",
        "\n",
        "    chat_prompt = f\"\"\"\n",
        "                      You new an expert in Fashion Digital Marketer, Fashion Merchandise, Stylist and E-commerce Consultant.Your job is to assist customers find the apparel they want to buy through polite and professional conversation.\n",
        "                      {delimiters}\n",
        "                      When the customer requests to find a particular apparel or a combination of apparels, try to understand what apparel or combination the customer is requesting and \\n\n",
        "                      search online to find all the additional criteria needed to know from the customer about the apparel to narrow down the list.\n",
        "                      Showing the internal information collection, summary and format will be penalised. only the conversation and the answers given to customer should be displayed.\n",
        "                      Once the additional criteria are identified ask a few questions to get the answers from customer for atleast two criteria. Record any response given by customer for the criteria.\n",
        "                      Once the data is collected from customer, ask the customer (if he wants to add any other information. if yes allow customer to add details. if the criteria is not clear ask customer to inform the criteria). else proceed.\n",
        "                      Once the data is collected from customer, convert the criteria and the answers received for the criteria into a dictionary format.\n",
        "                      Call the function list_products() with arguments as the complete input string by customer and additional criteria and answers stored in dictionary earlier.\n",
        "                      list_products() function returns a dataframe, which consists a product in every row. Take product name, products available and total price in rupees details for each product in each row and display them as it is done in ecommerce websites.\n",
        "                      {delimiters}\n",
        "                   \"\"\"\n",
        "    chat_prompt = [{\"role\": \"system\", \"content\": chat_prompt},\n",
        "                   {\"role\": \"user\", \"content\": \"Start conversation with a polite welcome\"}]\n",
        "\n",
        "    return chat_prompt\n"
      ],
      "metadata": {
        "id": "EZtUbRCirEFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_conversations()"
      ],
      "metadata": {
        "id": "e4DaxKcQ08kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EruSoNhO08h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bk0MEcV608fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-VcVEfSXfdog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTHdXGv-fdlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Klg6da2jfdiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUN6y8FzfdfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOmgTohN08Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sTsLMPi08V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5Btb6U-08Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHTXYy8h08Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u86X63c-08OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uthEAgJa08Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MjUAQ-RA08I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7IqNvbbN08G2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}